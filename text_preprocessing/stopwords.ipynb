{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965073e9-897d-408c-84be-21cb73848c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d755494-29f8-47f7-8b39-28af3b0b9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebce0e85-2fb9-4540-9b6b-22c55799fff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"U.S. lawmakers moved to revoke Russia’s normal trade status and ban its oil and gas, and the United Nations suspended the country from the Human Rights Council. The E.U. approved a phased-in ban on Russian coal, and NATO met to discuss military aid to Ukraine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51fd9e80-c4f8-49f4-b402-2b90613f8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_wrords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648bf37f-157a-4223-81c4-f7be690094df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49077d8-f029-4f9f-ac76-412388b12c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopdwords 전: ['U.S.', 'lawmakers', 'moved', 'to', 'revoke', 'Russia', '’', 's', 'normal', 'trade', 'status', 'and', 'ban', 'its', 'oil', 'and', 'gas', ',', 'and', 'the', 'United', 'Nations', 'suspended', 'the', 'country', 'from', 'the', 'Human', 'Rights', 'Council', '.', 'The', 'E.U', '.', 'approved', 'a', 'phased-in', 'ban', 'on', 'Russian', 'coal', ',', 'and', 'NATO', 'met', 'to', 'discuss', 'military', 'aid', 'to', 'Ukraine']\n",
      "Stopdwords 후: ['U.S.', 'lawmakers', 'moved', 'revoke', 'Russia', '’', 'normal', 'trade', 'status', 'ban', 'oil', 'gas', ',', 'United', 'Nations', 'suspended', 'country', 'Human', 'Rights', 'Council', '.', 'The', 'E.U', '.', 'approved', 'phased-in', 'ban', 'Russian', 'coal', ',', 'NATO', 'met', 'discuss', 'military', 'aid', 'Ukraine']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for word in tokenized_words :\n",
    "    if word not in stop_words:\n",
    "        result.append(word)\n",
    "    \n",
    "print(\"Stopdwords 전:\", tokenized_words)\n",
    "print(\"Stopdwords 후:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae5a2b-2e52-4b7f-a447-721fc68b60c4",
   "metadata": {},
   "source": [
    "#### 한국어 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458cc76b-3e73-41e4-8f84-38fb97ea2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "733f0a89-4ac0-4cdf-a37a-6653e19fc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"주말 1박에 조식 포함해 10만원대였던 방이 숙박대전이 시작하자마자 14만원대로 올라 쿠폰 3만원을 적용해도 숙박대전 이전보다 높은 가격에 묵어야 하는 상황\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f78409e-04d7-4055-865d-36038ec12593",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"은 는 이 가 시 로 을 를 이다 중\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6851a93f-7dbd-4113-b832-9f5e6fd5dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4eb69db-27d1-425c-99ec-783e7ca7e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = okt.morphs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b4d95f9-736e-4620-b5d3-416c2d05bbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 :  ['주말', '1', '박', '에', '조식', '포함', '해', '10만원', '대였던', '방이', '숙박', '대전', '이', '시작', '하', '자마자', '14만원', '대로', '올라', '쿠폰', '3만원', '을', '적용', '해도', '숙박', '대전', '이전', '보다', '높은', '가격', '에', '묵어야', '하는', '상황']\n"
     ]
    }
   ],
   "source": [
    "print(\"형태소 분석 : \", tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ab6624-80cf-4285-bbbb-8cb70d0c7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 처리 후  ['주말', '1', '박', '에', '조식', '포함', '해', '10만원', '대였던', '방이', '숙박', '대전', '시작', '하', '자마자', '14만원', '대로', '올라', '쿠폰', '3만원', '적용', '해도', '숙박', '대전', '이전', '보다', '높은', '가격', '에', '묵어야', '하는', '상황']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for word in tokenized_sentence :\n",
    "    if word not in stop_words :\n",
    "        result.append(word)\n",
    "        \n",
    "print(\"불용어 처리 후 \" , result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "494972ae-9cac-43b1-b6c3-9408c20fdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras's text preprocessing  토큰화 -> 수치화 (인코딩)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f30e3fab-9bd3-4ea0-a323-3fdf3aaa7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f12460bc-65f6-48b2-ba23-11e15e22e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ('The cat sat on the mat.', 'The dog ate my homework.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c431f44-5ac5-4bf2-98bd-6be658777723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 1000) # 사용 빈도가 높은 1000개를 토큰화\n",
    "tokenizer.fit_on_texts(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37b3e752-a7d7-4f9b-89bd-7221c024bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa30b127-d73a-4e72-9d33-1a0b7d0da694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "566518a6-c181-4c41-baf4-ba3de0bb10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 핫 인코딩 과정. to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "503b1682-f937-4aa1-9ac3-38e296c3f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502fdf11-6f91-47ee-94b7-f0771886f939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'mat': 5,\n",
       " 'dog': 6,\n",
       " 'ate': 7,\n",
       " 'my': 8,\n",
       " 'homework': 9}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index # 각 문장의 단어를 정수로 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "919ad66a-c130-488d-a963-02fed836bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer -> stemmer -> lemmatizer -> stopwords -> One hot Encoding --> To text preprocessing / nltk / konlpy / tokenize by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42171c67-1721-4308-b5ad-247cb589661c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
